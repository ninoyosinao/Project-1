{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import requests\n",
    "from config import api_key\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string \n",
    "\n",
    "sections = [\"Arts\", \"Automobiles\", \"Blogs\", \"Books\", \"Business Day\", \"Education\", \"Fashion & Style\", \"Food\", \"Health\", \"Job Market\", \"Magazine\", \n",
    "             \"membercenter\", \"Movies\", \"Multimedia\", \"N.Y.%20%2F%20Region\", \"NYT Now\", \"Obituaries\", \"Open\", \"Opinion\", \"Public Editor\", \"Real Estate\", \n",
    "             \"Science\", \"Sports\", \"Style\", \"Sunday Review\", \"T Magazine\", \"Technology\", \"The Upshot\", \"Theater\", \"Times Insider\", \"Today’s Paper\", \n",
    "             \"Travel\", \"U.S.\", \"World\", \"Your Money\"]\n",
    "\n",
    "url = \"https://api.nytimes.com/svc/mostpopular/v2/mostshared/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve articles\n",
    "words = []\n",
    "\n",
    "for section in sections:    \n",
    "    query_url = url + section + \"/30.json?api-key=\" + api_key\n",
    "\n",
    "    articles = requests.get(query_url).json()\n",
    "\n",
    "    # pprint(articles)\n",
    "    for i in range(len(articles[\"results\"])):\n",
    "        text = articles[\"results\"][i][\"title\"]\n",
    "        text = text.replace(\"-\", \" \")\n",
    "        text = text.replace(\"’s\", \"\")\n",
    "        text = text.replace(\"’ll\", \"\")\n",
    "        text = text.replace(\"’\", \"\")\n",
    "        text = text.replace(\"‘\", \"\")\n",
    "        text = text.replace(\"?\", \"\")\n",
    "        text = text.replace(\"!\", \"\")\n",
    "        text = text.replace(\":\", \"\")\n",
    "        text = text.replace(\",\", \"\")\n",
    "        text = text.replace(\".\", \"\")\n",
    "        text = text.replace(\";\", \"\")\n",
    "        text_split = text.split(\" \")\n",
    "\n",
    "        for word in text_split:\n",
    "    #         word = word.translate(str.maketrans({\":\":None, \"!\":None, \".\":None, \"?\": None, \",\": None}))\n",
    "            word = word.lower()\n",
    "            words.append(word)\n",
    "#     print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "the             112\n",
       "a                98\n",
       "to               61\n",
       "in               60\n",
       "of               58\n",
       "and              40\n",
       "is               38\n",
       "on               29\n",
       "for              27\n",
       "at               26\n",
       "trump            19\n",
       "it               18\n",
       "dies             15\n",
       "how              15\n",
       "with             14\n",
       "new              14\n",
       "review           13\n",
       "who              13\n",
       "what             12\n",
       "are              12\n",
       "that             12\n",
       "you              11\n",
       "an               11\n",
       "your             10\n",
       "as               10\n",
       "now               9\n",
       "                  9\n",
       "from              9\n",
       "this              9\n",
       "has               8\n",
       "               ... \n",
       "nesmith           1\n",
       "arm               1\n",
       "coach             1\n",
       "add               1\n",
       "enough            1\n",
       "book              1\n",
       "shibayama         1\n",
       "memory            1\n",
       "evokes            1\n",
       "worms             1\n",
       "spy               1\n",
       "rubble            1\n",
       "marker            1\n",
       "finally           1\n",
       "watch             1\n",
       "gay               1\n",
       "transforming      1\n",
       "too               1\n",
       "siri              1\n",
       "cardinal          1\n",
       "real              1\n",
       "tensions          1\n",
       "ideas             1\n",
       "straight          1\n",
       "theology          1\n",
       "hits              1\n",
       "met               1\n",
       "scotty            1\n",
       "flirts            1\n",
       "faces             1\n",
       "Name: Word, Length: 1481, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_df = pd.DataFrame({\"Word\": words})\n",
    "words_df[\"Word\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
